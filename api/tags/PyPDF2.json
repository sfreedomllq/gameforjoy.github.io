{"name":"PyPDF2","slug":"PyPDF2","count":1,"postlist":[{"title":"爬虫的具体应用：把gitbook变成自己的书库","slug":"爬虫的具体应用：把gitbook变成自己的书库","date":"2018-12-03T01:15:49.000Z","updated":"2018-12-04T12:15:28.470Z","comments":true,"path":"api/articles/爬虫的具体应用：把gitbook变成自己的书库.json","excerpt":"<h1 id=\"把gitbook变成自己的书库\"><a href=\"#把gitbook变成自己的书库\" class=\"headerlink\" title=\"把gitbook变成自己的书库\"></a>把gitbook变成自己的书库</h1><p>这篇文章中我们会从针对 gitbook 编写一个爬虫程序，该程序可以从 gitbook 网站中爬取我们想要的书并保存为pdf文件。主要应用到的技术点包括 beautifulsoup+requests， PyPDF2 。<br>为什么不用 scrapy？ 首先我们这种量级的爬虫程序用 scrapy 有点大材小用了。 其次，用 beautifulsoup+requests 可以帮助我们理解工作逻辑， 以及一些紧急措施的制定实行， 这在程序的编写中尤其重要。</p>\n<h2 id=\"思路-amp-准备\"><a href=\"#思路-amp-准备\" class=\"headerlink\" title=\"思路&amp;准备\"></a>思路&amp;准备</h2><p>思路很简单： beautifulSoup+requests 实现对需求数据的爬取， 然后进行一定的数据处理保存为html文件，再通过 PyPDF2 将保存好的html文件转换成pdf文件。<br><strong>准备：</strong></p>\n<ol>\n<li>安装 requests、 beautifulsoup、 pdfkit，reuqests 用于网络请求，beautifusoup 用于操作html数据， pdfkit 是 wkhtmltopdf 的Python封装包；</li>\n<li>安装 wkhtmltopdf，wkhtmltopdf 是一个适用于多平台的实现html对pdf转换的工具；</li>\n<li>安装 PyPDF2，此工具用于对pdf的融合。</li>\n</ol>","keywords":null,"cover":null,"content":null,"text":"把gitbook变成自己的书库这篇文章中我们会从针对 gitbook 编写一个爬虫程序，该程序可以从 gitbook 网站中爬取我们想要的书并保存为pdf文件。主要应用到的技术点包括 beautifulsoup+requests， PyPDF2 。<br>为什么不用 scrapy","link":"","raw":null,"photos":[],"categories":[{"name":"实践","slug":"实践","count":1,"path":"api/categories/实践.json"}],"tags":[{"name":"beautifulsoup","slug":"beautifulsoup","count":1,"path":"api/tags/beautifulsoup.json"},{"name":"requests","slug":"requests","count":1,"path":"api/tags/requests.json"},{"name":"PyPDF2","slug":"PyPDF2","count":1,"path":"api/tags/PyPDF2.json"},{"name":"gitbook","slug":"gitbook","count":1,"path":"api/tags/gitbook.json"},{"name":"爬虫","slug":"爬虫","count":2,"path":"api/tags/爬虫.json"}]}]}